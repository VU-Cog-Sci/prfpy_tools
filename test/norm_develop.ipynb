{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nb\n",
    "import os\n",
    "opj = os.path.join\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prfpy.stimulus import PRFStimulus2D\n",
    "from prfpy.grid import Iso2DGaussianGridder, Norm_Iso2DGaussianGridder\n",
    "from prfpy.fit import Iso2DGaussianFitter, Norm_Iso2DGaussianFitter\n",
    "from prfpy.timecourse import sgfilter_predictions\n",
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create stimulus\n",
    "dm_1R = create_dm_from_screenshots(screenshot_path='/Users/marcoaqil/PRFMapping/PRFMapping-Raw/sub-001/ses-1/rawdata/sub-001_ses-1_Logs/sub-001_ses-1_task-1R_run-1_Logs/Screenshots')\n",
    "dm_1S = create_dm_from_screenshots(screenshot_path='/Users/marcoaqil/PRFMapping/PRFMapping-Raw/sub-001/ses-1/rawdata/sub-001_ses-1_Logs/sub-001_ses-1_task-1S_run-1_Logs/Screenshots')\n",
    "dm_2R = create_dm_from_screenshots(screenshot_path='/Users/marcoaqil/PRFMapping/PRFMapping-Raw/sub-001/ses-1/rawdata/sub-001_ses-1_Logs/sub-001_ses-1_task-2R_run-1_Logs/Screenshots')\n",
    "dm_4F = create_dm_from_screenshots(screenshot_path='/Users/marcoaqil/PRFMapping/PRFMapping-Raw/sub-001/ses-1/rawdata/sub-001_ses-1_Logs/sub-001_ses-1_task-4F_run-1_Logs/Screenshots')\n",
    "dm_4R = create_dm_from_screenshots(screenshot_path='/Users/marcoaqil/PRFMapping/PRFMapping-Raw/sub-001/ses-1/rawdata/sub-001_ses-1_Logs/sub-001_ses-1_task-4R_run-1_Logs/Screenshots')\n",
    "\n",
    "discard_volumes = 5\n",
    "dm_full = np.concatenate((dm_1R[:,:,discard_volumes:],\n",
    "                          dm_1S[:,:,discard_volumes:],\n",
    "                          dm_2R[:,:,discard_volumes:],\n",
    "                          dm_4F[:,:,discard_volumes:],\n",
    "                          dm_4R[:,:,discard_volumes:]), axis=-1)\n",
    "\n",
    "prf_stim = PRFStimulus2D(screen_size_cm=70, \n",
    "                         screen_distance_cm=210, \n",
    "                         design_matrix=dm_full,\n",
    "                         TR=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/marcoaqil/PRFMapping/PRFMapping-Deriv-noflairtse-manual-hires'\n",
    "subj = 'sub-001'\n",
    "\n",
    "#create a single brain mask in epi space\n",
    "mask_dict = {}\n",
    "for task_name in ['1R', '1S', '2R', '4F', '4R']:\n",
    "    mask_ses_1 = nb.load(opj(data_path,'fmriprep/'+subj+'/ses-1/func/'+subj+'_ses-1_task-'+task_name+'_run-1_space-T1w_desc-brain_mask.nii.gz')).get_data().astype(bool)\n",
    "    mask_ses_2 = nb.load(opj(data_path, 'fmriprep/'+subj+'/ses-2/func/'+subj+'_ses-2_task-'+task_name+'_run-1_space-T1w_desc-brain_mask.nii.gz')).get_data().astype(bool)\n",
    "    \n",
    "    mask_dict[task_name] = mask_ses_1 + mask_ses_2\n",
    "    \n",
    "final_mask = mask_dict['1R'] + mask_dict['1S'] + mask_dict['2R'] + mask_dict['4F'] + mask_dict['4R']\n",
    "\n",
    "final_mask_2 = np.sum([mask_dict[key] for key in mask_dict])\n",
    "\n",
    "final_mask==final_mask_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing the data\n",
    "tc_dict = {}\n",
    "for task_name in ['1R', '1S', '2R', '4F', '4R']:\n",
    "    timecoursefile_ses_1 = nb.load(opj(deriv_path, 'fmriprep/'+subj+'/ses-1/func/'+subj+'_ses-1_task-'+task_name+'_run-1_space-T1w_desc-preproc_bold.nii.gz')\n",
    "    timecoursefile_ses_2 = nb.load(opj(deriv_path, 'fmriprep/'+subj+'/ses-2/func/'+subj+'_ses-2_task-'+task_name+'_run-1_space-T1w_desc-preproc_bold.nii.gz')\n",
    "       \n",
    "    timecourse_ses_1 = sgfilter_predictions(timecoursefile_ses_1.get_data()[:,:,:,discard_volumes:],\n",
    "                                            window_length=121)\n",
    "    timecourse_ses_2 = sgfilter_predictions(timecoursefile_ses_2.get_data()[:,:,:,discard_volumes:],\n",
    "                                            window_length=121)\n",
    "        \n",
    "    tc_dict[task_name] = (timecourse_ses_1+timecourse_ses_2)/2.0\n",
    "               \n",
    "\n",
    "\n",
    "timecourse_full=np.concatenate((tc_dict['1R'],tc_dict['1S'],tc_dict['2R'],tc_dict['4F'],tc_dict['4R']), axis=-1)\n",
    "                  \n",
    "#brain mask                  \n",
    "timecourse_brain = timecourse_full[final_mask]\n",
    "#exclude timecourses with zero variance\n",
    "timecourse_brain_nonzerovar = timecourse_brain[np.where(np.var(timecourse_brain, axis=-1)>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create gaussian grid\n",
    "grid_nr = 20\n",
    "max_ecc_size = 16\n",
    "sizes, eccs, polars = max_ecc_size * np.linspace(0.25,1,grid_nr)**2, \\\n",
    "                    max_ecc_size * np.linspace(0.1,1,grid_nr)**2, \\\n",
    "                        np.linspace(0, 2*np.pi, grid_nr)\n",
    "\n",
    "gg = Iso2DGaussianGridder(stimulus=prf_stim,\n",
    "                          filter_predictions=True,\n",
    "                          window_length=121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gf = Iso2DGaussianFitter(data=timecourse_brain_nonzerovar, gridder=gg, n_jobs=10)\n",
    "\n",
    "gf.grid_fit(ecc_grid=eccs,\n",
    "                 polar_grid=polars,\n",
    "                 size_grid=sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#refine Gaussian fits\n",
    "%%time\n",
    "gf.iterative_fit(rsq_threshold=0.05, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#now refit normalization model, starting from results of iterated Gaussian fitting\n",
    "gg_norm = Norm_Iso2DGaussianGridder(stimulus=prf_stim,\n",
    "                                   filter_predictions=True,\n",
    "                                   window_length=121)\n",
    "\n",
    "gf_norm = Norm_Iso2DGaussianFitter(data= timecourse_brain_nonzerovar,\n",
    "                                   gridder=gg_norm,\n",
    "                                   n_jobs=10)\n",
    "\n",
    "#have to add a column since in current code syntax\n",
    "#gridsearch_params always contains the CSS exponent parameter, even if it is not fit.\n",
    "#whereas iterative_search_params does not contain it if it is not fit)\n",
    "starting_params = np.insert(gf.iterative_search_params, -1, 1.0, axis=-1)\n",
    "\n",
    "gf_norm.iterative_fit(rsq_threshold=0.15, gridsearch_params=starting_params, verbose=True)\n",
    "\n",
    "current_result=np.copy(gf_norm.iterative_search_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#if needed, the normalization model iterative fit can be run again \n",
    "#(this makes sense only if changing some values in iterative_search minimization for increased precision)\n",
    "new_starting_params = np.insert(current_result, -1, 1.0, axis=-1)\n",
    "gf_norm.iterative_fit(rsq_threshold=0.0, gridsearch_params=new_starting_params, verbose=True)\n",
    "current_result=np.copy(gf_norm.iterative_search_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare rsq between models (ideally should be AIC or BIC)\n",
    "print(np.mean(gf_norm.iterative_search_params[gf_norm.rsq_mask,-1]))\n",
    "print(np.mean(gf.iterative_search_params[gf_norm.rsq_mask,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results for plotting\n",
    "\n",
    "attempt = np.zeros((78,102,80,10))\n",
    "ha = attempt.reshape((-1,10))\n",
    "ha[np.ravel(np.var(timecourse_brain, axis=-1)>0) & np.ravel(final_mask)]=gf_norm.iterative_search_params\n",
    "\n",
    "haha = ha.reshape((78,102,80,10))\n",
    "\n",
    "for i in range(10):\n",
    "    nb.Nifti1Image(haha[:,:,:,i], timecoursefile_ses_1.affine).to_filename('norm{}.nii.gz'.format(i))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
